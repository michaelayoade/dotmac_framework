name: Continuous Deployment

on:
  workflow_run:
    workflows: ["Continuous Integration"]
    types:
      - completed
    branches: [main]

env:
  REGISTRY: ghcr.io
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1

jobs:
  # Pre-deployment validation
  pre-deployment:
    name: Pre-deployment Validation
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    
    outputs:
      deploy-staging: ${{ steps.check.outputs.deploy-staging }}
      deploy-production: ${{ steps.check.outputs.deploy-production }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download deployment config
        uses: actions/download-artifact@v4
        with:
          name: deployment-config
          github-token: ${{ secrets.GITHUB_TOKEN }}
          run-id: ${{ github.event.workflow_run.id }}

      - name: Validate deployment readiness
        id: check
        run: |
          echo "Validating deployment readiness..."
          
          # Check if all required secrets are available
          if [[ -z "${{ secrets.DOCKER_REGISTRY_TOKEN }}" ]]; then
            echo "âŒ Docker registry token missing"
            exit 1
          fi
          
          # Always deploy to staging on main branch
          echo "deploy-staging=true" >> $GITHUB_OUTPUT
          
          # Deploy to production only on tagged releases
          if [[ "${{ github.ref }}" == refs/tags/* ]]; then
            echo "deploy-production=true" >> $GITHUB_OUTPUT
          else
            echo "deploy-production=false" >> $GITHUB_OUTPUT
          fi
          
          echo "âœ… Deployment validation complete"

  # Build and push Docker images
  build-images:
    name: Build & Push Images
    runs-on: ubuntu-latest
    needs: pre-deployment
    if: needs.pre-deployment.outputs.deploy-staging == 'true'
    
    strategy:
      matrix:
        service: 
          - name: isp-framework
            context: ./isp-framework
            dockerfile: ./isp-framework/Dockerfile
          - name: management-platform
            context: ./management-platform
            dockerfile: ./management-platform/Dockerfile
          - name: frontend-admin
            context: ./frontend
            dockerfile: ./frontend/apps/admin/Dockerfile
          - name: frontend-customer
            context: ./frontend
            dockerfile: ./frontend/apps/customer/Dockerfile
          - name: frontend-reseller
            context: ./frontend
            dockerfile: ./frontend/apps/reseller/Dockerfile
          - name: frontend-technician
            context: ./frontend
            dockerfile: ./frontend/apps/technician/Dockerfile
    
    outputs:
      image-tags: ${{ steps.meta.outputs.tags }}
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.DOCKER_REGISTRY_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ github.repository_owner }}/${{ matrix.service.name }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: ${{ matrix.service.context }}
          file: ${{ matrix.service.dockerfile }}
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            BUILDKIT_INLINE_CACHE=1

  # Deploy to staging environment
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [pre-deployment, build-images]
    if: needs.pre-deployment.outputs.deploy-staging == 'true'
    environment: staging
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name ${{ secrets.EKS_CLUSTER_NAME_STAGING }}

      - name: Deploy to Kubernetes
        run: |
          # Update image tags in deployment manifests
          export IMAGE_TAG=${{ github.sha }}
          envsubst < k8s/staging/deployment.yaml | kubectl apply -f -
          
          # Apply all staging configurations
          kubectl apply -f k8s/staging/
          
          # Wait for rollout to complete
          kubectl rollout status deployment/isp-framework -n staging --timeout=300s
          kubectl rollout status deployment/management-platform -n staging --timeout=300s
          kubectl rollout status deployment/frontend-admin -n staging --timeout=300s
          kubectl rollout status deployment/frontend-customer -n staging --timeout=300s
          kubectl rollout status deployment/frontend-reseller -n staging --timeout=300s
          kubectl rollout status deployment/frontend-technician -n staging --timeout=300s

      - name: Run smoke tests
        run: |
          # Wait for services to be ready
          sleep 30
          
          # Get service URLs
          ISP_URL=$(kubectl get service isp-framework -n staging -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          MGMT_URL=$(kubectl get service management-platform -n staging -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          
          # Run basic health checks
          curl -f "$ISP_URL/health" || exit 1
          curl -f "$MGMT_URL/health" || exit 1
          
          echo "âœ… Staging deployment successful and healthy"

      - name: Run integration tests against staging
        run: |
          # Run critical integration tests
          cd frontend
          STAGING_URL=https://staging.dotmac.com npm run test:integration:staging

  # Security scan of deployed environment
  security-scan-staging:
    name: Security Scan Staging
    runs-on: ubuntu-latest
    needs: deploy-staging
    
    steps:
      - name: OWASP ZAP Baseline Scan
        uses: zaproxy/action-baseline@v0.10.0
        with:
          target: 'https://staging.dotmac.com'
          rules_file_name: '.zap/rules.tsv'

      - name: Run security headers check
        run: |
          curl -s -D - https://staging.dotmac.com | grep -i security || true

  # Performance testing on staging
  performance-test-staging:
    name: Performance Test Staging
    runs-on: ubuntu-latest
    needs: deploy-staging
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18.x'

      - name: Install dependencies
        run: npm install -g lighthouse artillery

      - name: Run Lighthouse audit
        run: |
          lighthouse https://staging.dotmac.com --output=json --output-path=lighthouse-staging.json
          
      - name: Run load testing
        run: |
          artillery run tests/performance/load-test-staging.yml

      - name: Upload performance results
        uses: actions/upload-artifact@v4
        with:
          name: staging-performance-results
          path: |
            lighthouse-staging.json
            artillery-report.json

  # Deploy to production (manual approval required)
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [deploy-staging, security-scan-staging, performance-test-staging]
    if: needs.pre-deployment.outputs.deploy-production == 'true'
    environment: production
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name ${{ secrets.EKS_CLUSTER_NAME_PRODUCTION }}

      - name: Create database backup
        run: |
          # Create backup before deployment
          kubectl create job --from=cronjob/database-backup db-backup-pre-deploy -n production
          kubectl wait --for=condition=complete --timeout=300s job/db-backup-pre-deploy -n production

      - name: Deploy with blue-green strategy
        run: |
          # Blue-green deployment
          export IMAGE_TAG=${{ github.sha }}
          
          # Deploy to green environment
          envsubst < k8s/production/deployment-green.yaml | kubectl apply -f -
          
          # Wait for green deployment to be ready
          kubectl rollout status deployment/isp-framework-green -n production --timeout=600s
          kubectl rollout status deployment/management-platform-green -n production --timeout=600s
          kubectl rollout status deployment/frontend-admin-green -n production --timeout=600s
          kubectl rollout status deployment/frontend-customer-green -n production --timeout=600s
          kubectl rollout status deployment/frontend-reseller-green -n production --timeout=600s
          kubectl rollout status deployment/frontend-technician-green -n production --timeout=600s

      - name: Run production smoke tests
        run: |
          # Test green environment
          sleep 30
          
          # Run smoke tests against green environment
          GREEN_URL=$(kubectl get service isp-framework-green -n production -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')
          curl -f "$GREEN_URL/health" || exit 1
          
          # Run critical business logic tests
          cd frontend
          PRODUCTION_GREEN_URL=$GREEN_URL npm run test:smoke:production

      - name: Switch traffic to green
        run: |
          # Update service selectors to point to green deployment
          kubectl patch service isp-framework -n production -p '{"spec":{"selector":{"version":"green"}}}'
          kubectl patch service management-platform -n production -p '{"spec":{"selector":{"version":"green"}}}'
          kubectl patch service frontend-admin -n production -p '{"spec":{"selector":{"version":"green"}}}'
          kubectl patch service frontend-customer -n production -p '{"spec":{"selector":{"version":"green"}}}'
          kubectl patch service frontend-reseller -n production -p '{"spec":{"selector":{"version":"green"}}}'
          kubectl patch service frontend-technician -n production -p '{"spec":{"selector":{"version":"green"}}}'
          
          echo "âœ… Traffic switched to new version"

      - name: Monitor deployment
        run: |
          # Monitor for 5 minutes after deployment
          sleep 300
          
          # Check error rates and performance
          ERROR_RATE=$(kubectl top pods -n production | grep -c Error || echo 0)
          if [ "$ERROR_RATE" -gt 0 ]; then
            echo "âŒ High error rate detected, consider rollback"
            exit 1
          fi
          
          echo "âœ… Production deployment successful and stable"

      - name: Clean up blue environment
        run: |
          # Remove old blue deployment after successful green deployment
          sleep 300  # Wait 5 minutes before cleanup
          kubectl delete deployment isp-framework-blue -n production --ignore-not-found
          kubectl delete deployment management-platform-blue -n production --ignore-not-found
          kubectl delete deployment frontend-admin-blue -n production --ignore-not-found
          kubectl delete deployment frontend-customer-blue -n production --ignore-not-found
          kubectl delete deployment frontend-reseller-blue -n production --ignore-not-found
          kubectl delete deployment frontend-technician-blue -n production --ignore-not-found

  # Rollback capability
  rollback-production:
    name: Rollback Production
    runs-on: ubuntu-latest
    if: failure()
    environment: production
    
    steps:
      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Update kubeconfig
        run: |
          aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name ${{ secrets.EKS_CLUSTER_NAME_PRODUCTION }}

      - name: Rollback to previous version
        run: |
          echo "ðŸ”„ Rolling back to previous version..."
          
          # Switch traffic back to blue (previous version)
          kubectl patch service isp-framework -n production -p '{"spec":{"selector":{"version":"blue"}}}'
          kubectl patch service management-platform -n production -p '{"spec":{"selector":{"version":"blue"}}}'
          kubectl patch service frontend-admin -n production -p '{"spec":{"selector":{"version":"blue"}}}'
          kubectl patch service frontend-customer -n production -p '{"spec":{"selector":{"version":"blue"}}}'
          kubectl patch service frontend-reseller -n production -p '{"spec":{"selector":{"version":"blue"}}}'
          kubectl patch service frontend-technician -n production -p '{"spec":{"selector":{"version":"blue"}}}'
          
          echo "âœ… Rollback completed"

      - name: Notify team of rollback
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          text: "ðŸš¨ Production deployment failed and was rolled back. Manual intervention required."
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  # Post-deployment monitoring
  post-deployment:
    name: Post-deployment Monitoring
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: success()
    
    steps:
      - name: Setup monitoring alerts
        run: |
          echo "Setting up post-deployment monitoring..."
          # This would typically configure monitoring dashboards and alerts
          
      - name: Send success notification
        uses: 8398a7/action-slack@v3
        with:
          status: success
          text: "âœ… Production deployment successful! Version ${{ github.sha }} is now live."
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Create GitHub release
        if: github.ref_type == 'tag'
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: ${{ github.ref_name }}
          release_name: Release ${{ github.ref_name }}
          body: |
            Automated release from CD pipeline
            
            **Deployed Services:**
            - ISP Framework
            - Management Platform  
            - Frontend Applications (Admin, Customer, Reseller, Technician)
            
            **Commit:** ${{ github.sha }}
            **Build:** ${{ github.run_number }}
          draft: false
          prerelease: false