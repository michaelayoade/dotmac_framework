#!/usr/bin/env python3
import logging

logger = logging.getLogger(__name__)

"""
AI Code Detector - Identify AI-generated code patterns and flag risky changes.

This script analyzes code to identify patterns typical of AI-generated content
and flags potentially risky modifications that might affect business logic.
"""

import argparse
import ast
import json
import re
import sys
from pathlib import Path
from typing import Dict, List, Any, Set
import hashlib


class AICodeDetector:
    """
    Detector for AI-generated code patterns and risky modifications.
    """
    
    def __init__(self):
        self.ai_patterns = {
            # Common AI-generated comment patterns
            'ai_comments': [
                r'# AI-generated:',
                r'# Generated by AI',
                r'# Auto-generated by',
                r'# This code was generated',
                r'# Assistant generated',
                r'# Claude generated',
                r'# GPT generated',
            ],
            
            # AI-typical code patterns
            'ai_code_patterns': [
                r'def\s+\w+\s*\([^)]*\)\s*->\s*[^:]+:\s*"""[^"]*"""',  # Detailed type hints + docstrings
                r'assert\s+\w+\s+is\s+not\s+None,\s*["\'][^"\']*["\']',  # Defensive assertions
                r'if\s+isinstance\s*\([^)]+\):\s*pass',  # Type checking patterns
                r'try:\s*.*?\s*except\s+Exception\s+as\s+e:\s*.*?logger',  # Comprehensive error handling
            ],
            
            # Patterns indicating potential business logic changes
            'risky_patterns': [
                r'billing.*calculate',
                r'payment.*process',
                r'customer.*charge',
                r'invoice.*amount',
                r'price.*\*|rate.*\*',
                r'tax.*calculation',
                r'discount.*apply',
            ]
        }
        
        self.business_critical_files = {
            'billing',
            'payment',
            'invoice',
            'customer',
            'pricing',
            'tax',
            'revenue',
            'accounting'
        }
    
    def detect_ai_patterns(self, file_path: Path) -> Dict[str, Any]:
        """Detect AI-generated patterns in a file."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except Exception as e:
            return {'error': f"Failed to read {file_path}: {e}"}
        
        results = {
            'file': str(file_path),
            'ai_confidence': 0.0,
            'ai_indicators': [],
            'risky_changes': [],
            'business_critical': self._is_business_critical(file_path),
            'content_hash': hashlib.sha256(content.encode().hexdigest()[:16]
        }
        
        # Check for AI comment patterns
        for pattern in self.ai_patterns['ai_comments']:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                results['ai_indicators'].append({
                    'type': 'ai_comment',
                    'pattern': pattern,
                    'matches': len(matches),
                    'confidence': 0.9
                })
                results['ai_confidence'] += 0.3
        
        # Check for AI code patterns
        for pattern in self.ai_patterns['ai_code_patterns']:
            matches = re.findall(pattern, content, re.MULTILINE | re.DOTALL)
            if matches:
                results['ai_indicators'].append({
                    'type': 'ai_code_pattern',
                    'pattern': pattern,
                    'matches': len(matches),
                    'confidence': 0.6
                })
                results['ai_confidence'] += 0.2
        
        # Check for risky business logic patterns
        for pattern in self.ai_patterns['risky_patterns']:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                results['risky_changes'].append({
                    'pattern': pattern,
                    'matches': matches,
                    'severity': 'high' if results['business_critical'] else 'medium'
                })
        
        # Additional AI indicators
        self._check_code_structure(content, results)
        
        # Cap confidence at 1.0
        results['ai_confidence'] = min(results['ai_confidence'], 1.0)
        
        return results
    
    def _is_business_critical(self, file_path: Path) -> bool:
        """Check if file contains business-critical code."""
        path_str = str(file_path).lower()
        return any(critical in path_str for critical in self.business_critical_files)
    
    def _check_code_structure(self, content: str, results: Dict[str, Any]):
        """Analyze code structure for AI patterns."""
        try:
            tree = ast.parse(content)
            
            # Count defensive patterns typical of AI
            defensive_count = 0
            comprehensive_error_handling = 0
            
            for node in ast.walk(tree):
                # Defensive assertions
                if isinstance(node, ast.Assert):
                    defensive_count += 1
                
                # Comprehensive try-except blocks
                if isinstance(node, ast.Try):
                    if len(node.handlers) > 1 or (
                        node.handlers and 
                        isinstance(node.handlers[0].type, ast.Name) and 
                        node.handlers[0].type.id == 'Exception'
                    ):
                        comprehensive_error_handling += 1
            
            if defensive_count > 3:
                results['ai_indicators'].append({
                    'type': 'defensive_coding',
                    'count': defensive_count,
                    'confidence': 0.4
                })
                results['ai_confidence'] += 0.1
            
            if comprehensive_error_handling > 2:
                results['ai_indicators'].append({
                    'type': 'comprehensive_error_handling',
                    'count': comprehensive_error_handling,
                    'confidence': 0.5
                })
                results['ai_confidence'] += 0.15
                
        except SyntaxError:
            # File might not be valid Python
            pass
    
    def scan_directory(self, directory: Path) -> List[Dict[str, Any]]:
        """Scan directory for AI-generated code."""
        results = []
        
        for py_file in directory.rglob("*.py"):
            if self._should_skip_file(py_file):
                continue
                
            file_results = self.detect_ai_patterns(py_file)
            if file_results.get('ai_confidence', 0) > 0.3 or file_results.get('risky_changes'):
                results.append(file_results)
        
        return results
    
    def _should_skip_file(self, file_path: Path) -> bool:
        """Check if file should be skipped."""
        skip_patterns = [
            '__pycache__',
            '.pytest_cache',
            '.mypy_cache',
            'venv',
            'virtualenv',
            '.git',
            'migrations',
            'tests/generated',
            'tests/ai_generated'
        ]
        
        path_str = str(file_path)
        return any(pattern in path_str for pattern in skip_patterns)
    
    def generate_report(self, results: List[Dict[str, Any]], output_file: str = None) -> Dict[str, Any]:
        """Generate comprehensive report of AI code detection."""
        report = {
            'summary': {
                'total_files_scanned': len(results),
                'ai_generated_files': len([r for r in results if r.get('ai_confidence', 0) > 0.7]),
                'potentially_ai_files': len([r for r in results if 0.3 < r.get('ai_confidence', 0) <= 0.7]),
                'business_critical_changes': len([r for r in results if r.get('business_critical') and r.get('risky_changes')]),
                'total_risky_changes': sum(len(r.get('risky_changes', []) for r in results)
            },
            'high_risk_files': [
                r for r in results 
                if r.get('business_critical') and (
                    r.get('risky_changes') or r.get('ai_confidence', 0) > 0.7
                )
            ],
            'ai_generated_files': [
                r for r in results 
                if r.get('ai_confidence', 0) > 0.7
            ],
            'all_results': results
        }
        
        if output_file:
            with open(output_file, 'w') as f:
                json.dump(report, f, indent=2)
        
        return report


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(description='Detect AI-generated code and flag risky changes')
    parser.add_argument('--directory', '-d', default='src', help='Directory to scan')
    parser.add_argument('--output', '-o', help='Output JSON file')
    parser.add_argument('--flag-risky', action='store_true', help='Flag risky business logic changes')
    parser.add_argument('--fail-on-risk', action='store_true', help='Exit with error code if risky changes found')
    parser.add_argument('--verbose', '-v', action='store_true', help='Verbose output')
    
    args = parser.parse_args()
    
    detector = AICodeDetector()
    directory = Path(args.directory)
    
    if not directory.exists():
logger.error(f"Error: Directory {directory} does not exist", file=sys.stderr)
        sys.exit(1)
    
logger.info(f"Scanning {directory} for AI-generated code patterns...")
    results = detector.scan_directory(directory)
    
    if not results:
logger.info("No AI-generated code patterns detected.")
        sys.exit(0)
    
    report = detector.generate_report(results, args.output)
    
    # Print summary
    summary = report['summary']
logger.info(f"\n📊 AI Code Detection Summary:")
logger.info(f"   Files scanned: {summary['total_files_scanned']}")
logger.info(f"   AI-generated files: {summary['ai_generated_files']}")
logger.info(f"   Potentially AI files: {summary['potentially_ai_files']}")
logger.info(f"   Business-critical changes: {summary['business_critical_changes']}")
logger.info(f"   Total risky changes: {summary['total_risky_changes']}")
    
    # Flag high-risk files
    if args.flag_risky and report['high_risk_files']:
logger.info(f"\n⚠️  HIGH RISK FILES DETECTED:")
        for file_info in report['high_risk_files']:
logger.info(f"   📄 {file_info['file']}")
logger.info(f"      AI Confidence: {file_info['ai_confidence']:.2f}")
            if file_info.get('risky_changes'):
logger.info(f"      Risky Changes: {len(file_info['risky_changes'])}")
                for change in file_info['risky_changes']:
logger.info(f"        - {change['pattern']} (severity: {change['severity']})")
    
    if args.verbose:
logger.info(f"\n🔍 Detailed Results:")
        for result in results:
logger.info(f"\n📄 {result['file']}")
logger.info(f"   AI Confidence: {result['ai_confidence']:.2f}")
logger.info(f"   Business Critical: {result['business_critical']}")
            if result['ai_indicators']:
logger.info(f"   AI Indicators:")
                for indicator in result['ai_indicators']:
logger.info(f"     - {indicator['type']}: {indicator.get('matches', indicator.get('count', 1')}")
    
    # Exit with error if risky changes found and flag is set
    if args.fail_on_risk and summary['business_critical_changes'] > 0:
logger.error(f"\n❌ Exiting with error due to {summary['business_critical_changes']} business-critical changes")
        sys.exit(1)
    
    if args.output:
logger.info(f"\n📝 Detailed report saved to: {args.output}")


if __name__ == '__main__':
    main()